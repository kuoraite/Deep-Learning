{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "by Simona KuoraitÄ— 2110586 <br>\n",
        "Model: resnet101 <br>\n",
        "DataSet: 1000 images, 3 classes: Dog, Cat, Bird"
      ],
      "metadata": {
        "id": "15_8kgBcYD8j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nitNae0N-YDS"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install torch torchvision\n",
        "!pip install opencv-contrib-python\n",
        "!pip install openimages\n",
        "!pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "FrZZOq3PpKDE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from collections import defaultdict\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sn\n",
        "\n",
        "from PIL import Image\n",
        "from openimages.download import download_dataset\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "from torchvision import models\n",
        "from torchvision import transforms\n",
        "from torchvision.models import resnet101, ResNet101_Weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fEJ6uOWrd77"
      },
      "source": [
        "Downloading the DataSet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "b59aaVf9pIqj"
      },
      "outputs": [],
      "source": [
        "data_directory = \"data\"\n",
        "total_samples = 1000\n",
        "classes = [\"Dog\", \"Cat\", \"Bird\"]\n",
        "\n",
        "if not os.path.exists(data_directory):\n",
        "    os.makedirs(data_directory)\n",
        "\n",
        "limit_per_class = total_samples // len(classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "i8ZGAycupXWM",
        "outputId": "958fe667-c3ba-437c-ab07-cfac7fca5cee"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-a1d773ef06d8>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdownload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit_per_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openimages/download.py\u001b[0m in \u001b[0;36mdownload_dataset\u001b[0;34m(dest_dir, class_labels, exclusions_path, annotation_format, csv_dir, limit)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;31m# get a dictionary of class labels to GroupByDataFrames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;31m# containing bounding box info grouped by image IDs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0mlabel_bbox_groups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_group_bounding_boxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_section\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_codes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclusion_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsv_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlabel_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_label\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openimages/download.py\u001b[0m in \u001b[0;36m_group_bounding_boxes\u001b[0;34m(section, label_codes, exclusion_ids, csv_dir)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;31m# filter the DataFrame down to just the images for the class label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m         \u001b[0mdf_label_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"LabelName\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mclass_code\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0;31m# drop the label name column since it's no longer needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/ops/common.py\u001b[0m in \u001b[0;36mnew_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/arraylike.py\u001b[0m in \u001b[0;36m__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__eq__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__eq__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cmp_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__ne__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   6241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6242\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6243\u001b[0;31m             \u001b[0mres_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomparison_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6245\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_construct_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m         \u001b[0mres_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomp_method_OBJECT_ARRAY\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36mcomp_method_OBJECT_ARRAY\u001b[0;34m(op, x, y)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvec_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalar_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "download_dataset(data_directory, classes, limit=limit_per_class)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7O_8FJ4KsBbi"
      },
      "source": [
        "Getting the DataSet ready <br>\n",
        "resnet101 expects input images to be normalized with mean [0.485, 0.456, 0.406] and standard deviation [0.229, 0.224, 0.225]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RqNiOtm-4erV"
      },
      "outputs": [],
      "source": [
        "custom_transform = transforms.Compose([\n",
        " transforms.Resize(256),\n",
        " transforms.CenterCrop(224),\n",
        " transforms.ToTensor(),\n",
        " transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        " ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLR5gWeIzJwc"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, data_folder, transform=None):\n",
        "    self.data_folder = data_folder\n",
        "    self.classes = os.listdir(data_folder)\n",
        "    self.transform = transform\n",
        "\n",
        "  def __len__(self):\n",
        "    total_samples = 0\n",
        "    for class_ in self.classes:\n",
        "      class_folder = os.path.join(self.data_folder, class_)\n",
        "      for folder in os.listdir(os.path.join(self.data_folder, class_)):\n",
        "        total_samples += len(os.listdir(os.path.join(class_folder, folder)))\n",
        "    return total_samples\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    class_index = index % len(self.classes)\n",
        "    class_folder = os.path.join(self.data_folder, self.classes[class_index], 'images')\n",
        "    image_index = index // len(self.classes)\n",
        "    image_name = os.listdir(class_folder)[image_index]\n",
        "    image_path = os.path.join(class_folder, image_name)\n",
        "\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "    if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "\n",
        "    label = self.classes[class_index]\n",
        "\n",
        "    return (image, label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7X8Y4qJ13QqF"
      },
      "outputs": [],
      "source": [
        "class CustomDataLoader:\n",
        "    def __init__(self, dataset, batch_size):\n",
        "        self.dataset = dataset\n",
        "        self.batch_size = batch_size\n",
        "        self.num_samples = len(dataset)\n",
        "        self.num_batches = (self.num_samples + batch_size - 1) // batch_size\n",
        "        self.current_batch = 0\n",
        "\n",
        "    def __iter__(self):\n",
        "        return self\n",
        "\n",
        "    def __next__(self):\n",
        "        if self.current_batch < self.num_batches:\n",
        "            start_index = self.current_batch * self.batch_size\n",
        "            end_index = min((self.current_batch + 1) * self.batch_size, self.num_samples)\n",
        "            batch_data = [self.dataset[i] for i in range(start_index, end_index)]\n",
        "            self.current_batch += 1\n",
        "            return batch_data\n",
        "        else:\n",
        "            raise StopIteration"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Incorporating all images from the dataset into the model and retrieving softmax predictions for each image"
      ],
      "metadata": {
        "id": "3hrgdt-6Y-ww"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "woPN9lA65-hw"
      },
      "outputs": [],
      "source": [
        "class_names = os.listdir('/content/data')\n",
        "num_classes = len(class_names)\n",
        "\n",
        "model = resnet101(weights=ResNet101_Weights.DEFAULT, progress=False)\n",
        "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "\n",
        "batch = 32\n",
        "number_of_batches = (999 + batch - 1) // batch\n",
        "\n",
        "custom_dataset = CustomDataset(data_folder='/content/data', transform=custom_transform)\n",
        "custom_dataloader = CustomDataLoader(dataset=custom_dataset, batch_size=batch)\n",
        "\n",
        "current_iteration = 0\n",
        "probability_arr = []\n",
        "classes_arr = []\n",
        "\n",
        "model.eval()\n",
        "\n",
        "for batch_data in custom_dataloader:\n",
        "  print(f\"Current batch iteration: {current_iteration} Batches left: {(total_samples + batch - 1) // batch - current_iteration}\")\n",
        "  (images, labels) = zip(*batch_data)\n",
        "  for image, label in zip(images, labels):\n",
        "    with torch.no_grad():\n",
        "      output = model(image.unsqueeze(0))\n",
        "\n",
        "    softmax = nn.Softmax(dim=1)\n",
        "    probabilities = softmax(output)\n",
        "\n",
        "    probability_arr.append(probabilities)\n",
        "    classes_arr.append(label)\n",
        "\n",
        "  current_iteration += 1\n",
        "\n",
        "print(\"Done\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 0.3\n",
        "\n",
        "predicted_class_arr = []\n",
        "actual_class_arr = []\n",
        "element = 0\n",
        "\n",
        "for probability_tensor in probability_arr:\n",
        "  indices_tensor = torch.nonzero(probability_tensor > threshold, as_tuple=False)\n",
        "  indices_list = indices_tensor[:, 1].tolist()\n",
        "\n",
        "  predictions = [class_names[index] for index in indices_list]\n",
        "\n",
        "  if len(predictions) > 0:\n",
        "        for prediction in predictions:\n",
        "            predicted_class_arr.append(prediction)\n",
        "            actual_class_arr.append(classes_arr[element])\n",
        "\n",
        "  element += 1"
      ],
      "metadata": {
        "id": "l7kjLV4zGZhT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXe5HCEHIyBa"
      },
      "source": [
        "Calculate Statistics:\n",
        "* accuracy = (TN + TP)/(TP+TN+FP+FN)\n",
        "* precision = TP/TP+FP. Precision - the percentage of positive guesses that were true.\n",
        "* recall = TP/TP+FN. Recall - the percentage of positive test examples classified as positive.\n",
        "* F1 = (2 * precision * recall)/(precision + recall). F1 - a middle ground between precision and recall.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UqyEdXZlmPYb"
      },
      "outputs": [],
      "source": [
        "cf_matrix = confusion_matrix(predicted_class_arr, actual_class_arr, labels=class_names)\n",
        "if cf_matrix.shape == (1, 1):\n",
        "    cf_matrix = np.zeros((len(class_names), len(class_names)))\n",
        "\n",
        "# Create a DataFrame with the confusion matrix and class indices\n",
        "df_cm = pd.DataFrame(cf_matrix, index=class_names, columns=class_names)\n",
        "plt.figure(figsize = (12,7))\n",
        "sn.heatmap(df_cm, annot=True, fmt='g')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "33tiK17Ipok9"
      },
      "outputs": [],
      "source": [
        "class_names = os.listdir('/content/data')\n",
        "\n",
        "accuracy_sum, precision_sum, recall_sum, f1_sum = 0, 0, 0, 0\n",
        "\n",
        "for i in range(3):\n",
        "  print(f\"Class: {class_names[i]}\")\n",
        "  TP = df_cm.iloc[i,i]\n",
        "  FP = df_cm.iloc[i,:].sum() - TP\n",
        "  FN = df_cm.iloc[:,i].sum()\n",
        "  TN = df_cm.sum().sum() - TP - FP - FN\n",
        "\n",
        "  accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
        "  precision = TP / (TP + FP)\n",
        "  recall = TP / (TP + FN)\n",
        "  f1 = (2 * precision * recall)/(precision + recall)\n",
        "\n",
        "  accuracy_sum += accuracy\n",
        "  precision_sum += precision\n",
        "  recall_sum += recall\n",
        "  f1_sum += f1\n",
        "\n",
        "  print(f\"accuracy: {accuracy:.2f}\")\n",
        "  print(f\"precision: {precision:.2f}\")\n",
        "  print(f\"recall: {recall:.2f}\")\n",
        "  print(f\"F1: {f1:.2f}\")\n",
        "  print(\"\")\n",
        "\n",
        "print(f\"accuracy mean: {(accuracy_sum / 3):.2f}\")\n",
        "print(f\"precision mean: {(precision_sum / 3):.2f}\")\n",
        "print(f\"recall mean: {(recall_sum / 3):.2f}\")\n",
        "print(f\"F1 mean: {(f1_sum / 3):.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1REx-KXo7CVS"
      },
      "source": [
        "Classifying a random image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NjI0nrQYv1B1"
      },
      "outputs": [],
      "source": [
        "image = Image.open('/content/testImages/cat.png').convert(\"RGB\")\n",
        "image = custom_transform(image)\n",
        "\n",
        "output = model(image.unsqueeze(0))\n",
        "softmax = nn.Softmax(dim=1)\n",
        "probabilities = softmax(output)\n",
        "\n",
        "predicted_class_index = torch.argmax(probabilities, dim=1).item()\n",
        "predicted_class = class_names[predicted_class_index]\n",
        "\n",
        "print(predicted_class)\n",
        "\n",
        "plt.imshow(image.permute(1, 2, 0))\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}